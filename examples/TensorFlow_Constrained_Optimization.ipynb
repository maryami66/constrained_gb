{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow_Constrained_Optimization.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkqOEOmTzb-a"
      },
      "source": [
        "# TensorFlow Constrained Optimization Tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH5IK60Gzdnw"
      },
      "source": [
        "Constrains a class tensorflow_constrained_optimization for safety constraint (FNR < alpha)\n",
        "and an example for a simple dataset and simple fully connected neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcwJzQ3szgIn"
      },
      "source": [
        "Note: This tutorial has been run on google colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12FG5hEsxL11"
      },
      "source": [
        "# Install the toolbox\n",
        "!pip install git+https://github.com/google-research/tensorflow_constrained_optimization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCX8v9sfxWRp"
      },
      "source": [
        "# import libraries:\n",
        "\n",
        "# tensorflow and keras\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_constrained_optimization as tfco\n",
        "\n",
        "# sckit-learn\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import *\n",
        "\n",
        "# others\n",
        "import os\n",
        "import tempfile\n",
        "import numpy as np"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vG9m45rzm6B"
      },
      "source": [
        "## Class for Safe Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82sJ4R3eyTfB"
      },
      "source": [
        "class ConstrainedModel:\n",
        "    \"\"\"A class using constrained optimization in Keras Model\n",
        "    This class works only constrained on false negative rate\n",
        "    Constraint is: FNR < alpha\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, **kwargs):\n",
        "        self.model = model\n",
        "\n",
        "    ############# Training ##################\n",
        "    def fit(self, X_train, y_train, batch_size, epochs, learning_rate, alpha):\n",
        "        \n",
        "        # Split the training set to Train and Valdation\n",
        "        X_train, X_vali, y_train, y_vali = train_test_split(X_train, y_train, test_size=0.2)\n",
        "        \n",
        "        # for training purpose\n",
        "        num_examples = X_train.shape[0]\n",
        "\n",
        "\n",
        "        # Create features and labels tensors to hold minibatch content.\n",
        "        batch_shape = (batch_size, X_train.shape[1])\n",
        "        features_tensor = tf.Variable(np.zeros(batch_shape, dtype=\"int32\"), name=\"features\")\n",
        "\n",
        "        batch_shape = (batch_size, 1)\n",
        "        labels_tensor = tf.Variable(np.zeros(batch_shape, dtype=\"float32\"), name=\"labels\")\n",
        "\n",
        "        # The prediction tensor is used in the constext\n",
        "        def predictions():\n",
        "            return self.model(features_tensor)\n",
        "        \n",
        "        # Set up separate contexts.\n",
        "        context = tfco.rate_context(predictions, lambda: labels_tensor)\n",
        "\n",
        "\n",
        "        # Compute the objective: This is the loss function\n",
        "        objective = tfco.error_rate(context)\n",
        "        \n",
        "        # Set the constraints\n",
        "        constraints = [tfco.false_negative_rate(context) <= alpha]\n",
        "\n",
        "        # Create a rate minimization problem.\n",
        "        problem = tfco.RateMinimizationProblem(objective, constraints)\n",
        "        \n",
        "        # Set up a constrained optimizer.\n",
        "        optimizer = tfco.ProxyLagrangianOptimizerV2(\n",
        "          optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "          num_constraints=problem.num_constraints)\n",
        "\n",
        "        # the constrained optimizer.\n",
        "        var_list = (self.model.trainable_weights + problem.trainable_variables +\n",
        "                    optimizer.trainable_variables())\n",
        "\n",
        "        \n",
        "        # this is the function for computing constraint violation\n",
        "        def false_negative_rate(labels, predictions):\n",
        "          if np.sum(labels > 0) == 0:  # Any positives?\n",
        "            return 0.0\n",
        "          else:\n",
        "            return np.mean(predictions[labels > 0] <= 0)\n",
        "\n",
        "        \n",
        "        # Create temporary directory to record model snapshots.\n",
        "        temp_directory = tempfile.mktemp()\n",
        "        os.mkdir(temp_directory)\n",
        "\n",
        "        # List of recorded objectives and constrained violations.\n",
        "        objectives_list = []\n",
        "        violations_list = []\n",
        "\n",
        "        # Loop over minibatches.\n",
        "        for batch_index in range(epochs):\n",
        "            # Indices for current minibatch in the first stream.\n",
        "            batch_indices = np.arange(batch_index * batch_size, (batch_index + 1) * batch_size)\n",
        "            batch_indices = [ind % num_examples for ind in batch_indices]\n",
        "\n",
        "            # Assign features, labels, groups from the minibatches to the respective tensors.\n",
        "            features_tensor.assign(X_train[batch_indices, :])\n",
        "\n",
        "            labels_tensor.assign(y_train[batch_indices])\n",
        "\n",
        "            # Gradient update.\n",
        "            optimizer.minimize(problem, var_list=var_list)\n",
        "            \n",
        "            # To record the error and contrainted violations\n",
        "            scores = self.model.predict(X_vali)\n",
        "            error = self.error_rate(y_vali, scores)\n",
        "\n",
        "            fnrs = false_negative_rate(\n",
        "              y_vali, scores)\n",
        "            violations = [fnrs - alpha]\n",
        "\n",
        "            objectives_list.append(error)\n",
        "            violations_list.append(violations)\n",
        "\n",
        "            # Save model weights to temporary directory.\n",
        "            self.model.save_weights(\n",
        "              temp_directory + \"constrained_\" +\n",
        "              str(int(batch_index)) + \".h5\")\n",
        "              \n",
        "        \n",
        "        \n",
        "        # Select the best model from the recorded iterates using TFCO's find best\n",
        "        # candidates heuristic.\n",
        "        best_index = tfco.find_best_candidate_index(\n",
        "          np.array(objectives_list), np.array(violations_list), rank_objectives=False)\n",
        "              \n",
        "        # Load model weights for the best iterate from the snapshots saved previously.\n",
        "        self.model.load_weights(\n",
        "          temp_directory + \"constrained_\" + str(best_index) + \".h5\")\n",
        "\n",
        "    ################### Evaluation #######################\n",
        "    def error_rate(self, y_true, y_pred):\n",
        "        # Returns error rate for given labels and predictions.\n",
        "        # Recall that the labels are binary (0 or 1).\n",
        "        signed_labels = (y_true * 2) - 1\n",
        "        return np.mean(signed_labels * y_pred <= 0.0)\n",
        "    \n",
        "    def false_negative_rate(self, y_true, y_pred):\n",
        "        # Returns false negative rate for given labels and predictions.\n",
        "        if np.sum(y_true > 0) == 0:  # Any positives?\n",
        "            return 0.0\n",
        "        else:\n",
        "            return np.mean(y_pred[y_true > 0] <= 0)\n",
        "\n",
        "    def false_positive_rate(self, y_true, y_pred):\n",
        "        # Returns false positive rate for given labels and predictions.\n",
        "        if np.sum(y_true <= 0) == 0:  # Any negatives?\n",
        "            return 0.0\n",
        "        else:\n",
        "            return np.mean(y_pred[y_true <= 0] > 0)\n",
        "\n",
        "    def evaluate(self, X_test, y_test, verbose=0):\n",
        "\n",
        "        y_true = y_test.reshape(-1, 1)\n",
        "        y_pred = (self.model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "        f1_measure = f1_score(y_true, y_pred)\n",
        "        \n",
        "        fn_rate = self.false_negative_rate(y_true, y_pred)\n",
        "        fp_rate = self.false_positive_rate(y_true, y_pred)\n",
        "\n",
        "        if verbose == 1:\n",
        "            print(\"F1 Measure: {}\".format(f1_measure))\n",
        "            print(\"False Negative error: {}\".format(fn_rate))\n",
        "            print(\"False Positive error: {}\".format(fp_rate))\n",
        "\n",
        "        \n",
        "        result = {'F1 Measure': f1_measure, 'False Negative error': fn_rate, 'False Positive error': fp_rate}\n",
        "        self.result = result"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTb0MmpHzsQ5"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htI6FSrRyUqJ"
      },
      "source": [
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=2)\n",
        "y_train = y_train.reshape(-1, 1)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vwi1UKPizvwN"
      },
      "source": [
        "## Set the hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvRaYQEVybeZ"
      },
      "source": [
        "params = {\n",
        "    'alpha': 0.1,\n",
        "    'nb_epoch': 100,\n",
        "    'batch_size': 20,\n",
        "    'learning_rate': 0.001}"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-pqGFNzzyCA"
      },
      "source": [
        "## Train the Constrained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MLTegn3ydxI"
      },
      "source": [
        "def create_model():\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Dense(26, input_shape=(X_train.shape[1],),\n",
        "                           activation='relu'))\n",
        "\n",
        "    model.add(layers.Dense(1))\n",
        "    return model"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E7Q10-RygVY",
        "outputId": "4be5d2a9-4514-469d-825f-df6db04a8d13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# Set random seed.\n",
        "np.random.seed(232312)\n",
        "tf.random.set_seed(323221)\n",
        "model = create_model()\n",
        "constrained_model = ConstrainedModel(model)\n",
        "\n",
        "# fit the constrained model\n",
        "constrained_model.fit(X_train, y_train,\n",
        "                      batch_size=params['batch_size'], epochs=params['nb_epoch'],\n",
        "                      learning_rate=params['learning_rate'], alpha=params['alpha'])\n",
        "constrained_model.evaluate(X_test, y_test, verbose=1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 Measure: 0.7389380530973452\n",
            "False Negative error: 0.045714285714285714\n",
            "False Positive error: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}